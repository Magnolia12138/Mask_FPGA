{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pynq.overlays.base import BaseOverlay\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pynq.lib.video import *\n",
    "from time import sleep\n",
    "base = BaseOverlay(\"base.bit\")\n",
    "#加入自己ip后重构的overlay\n",
    "from pynq.lib import MicroblazeLibrary\n",
    "pAudio = base.audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capture device is open: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# monitor configuration: 640*480 @ 60Hz\n",
    "screen_w=320\n",
    "screen_h=240\n",
    "Mode = VideoMode(640,480,24)\n",
    "hdmi_out = base.video.hdmi_out\n",
    "hdmi_out.configure(Mode,PIXEL_BGR)\n",
    "hdmi_out.start()\n",
    "\n",
    "\n",
    "pAudio.select_microphone()\n",
    "\n",
    "\n",
    "# monitor (output) frame buffer size\n",
    "frame_out_w = screen_w\n",
    "frame_out_h = screen_h\n",
    "\n",
    "# camera (input) configuration\n",
    "frame_in_w = screen_w\n",
    "frame_in_h = screen_h\n",
    "sleep(10)\n",
    "# initialize camera from OpenCV\n",
    "videoIn = cv2.VideoCapture(0)\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_WIDTH, frame_in_w);\n",
    "videoIn.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_in_h);\n",
    "print(\"Capture device is open: \" + str(videoIn.isOpened()))\n",
    "np_frame=0\n",
    "\n",
    "# -*- coding:utf-8 -*-\n",
    "import os\n",
    "# 检测人脸\n",
    "def detect_face(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier('/home/xilinx/jupyter_notebooks/base/video/data/'\n",
    "    'haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5)\n",
    "    if (len(faces) == 0):\n",
    "        return None, None\n",
    "    (x, y, w, h) = faces[0]\n",
    "    return gray[y:y + w, x:x + h], faces[0]\n",
    " \n",
    "# 该函数将读取所有的训练图像，从每个图像检测人脸并将返回两个相同大小的列表，分别为脸部信息和标签\n",
    "def prepare_training_data(data_folder_path):\n",
    "    dirs = os.listdir(data_folder_path)\n",
    "    faces = []\n",
    "    labels = []\n",
    "    for dir_name in dirs:\n",
    "        if not dir_name == '.ipynb_checkpoints':\n",
    "            label = int(dir_name)\n",
    "        subject_dir_path = data_folder_path + \"/\" + dir_name\n",
    "        subject_images_names = os.listdir(subject_dir_path)\n",
    "        for image_name in subject_images_names:\n",
    "            if not dir_name == '.ipynb_checkpoints':\n",
    "                image_path = subject_dir_path + \"/\" + image_name\n",
    "                image = cv2.imread(image_path)\n",
    "                face, rect = detect_face(image)\n",
    "                if face is not None:\n",
    "                    faces.append(face)\n",
    "                    labels.append(label)\n",
    "    #最终返回值为人脸和标签列表\n",
    "    return faces, labels\n",
    "\n",
    "#根据给定的（x，y）坐标和宽度高度在图像上绘制矩形\n",
    "def draw_rectangle(img, rect):\n",
    "    (x, y, w, h) = rect\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (128, 128, 0), 2)\n",
    "\n",
    "# 根据给定的（x，y）坐标标识出人名\n",
    "def draw_text(img, text, x, y):\n",
    "    cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_COMPLEX, 1, (128, 128, 0), 2)\n",
    "\n",
    "# 此函数识别传递的图像中的人物并在检测到的脸部周围绘制一个矩形及其名称\n",
    "def predict(test_img):\n",
    "    img = test_img.copy()\n",
    "    face, rect = detect_face(img)\n",
    "    if not face is None:\n",
    "        label = face_recognizer.predict(face)\n",
    "        if label[1]<140:\n",
    "            label_text = subjects[label[0]]\n",
    "        else:\n",
    "            label_text = subjects[0]\n",
    "        draw_rectangle(img, rect)\n",
    "        draw_text(img, label_text, rect[0], rect[1] - 5)\n",
    "    else:\n",
    "        draw_text(img, 'nofound',0,20)\n",
    "\n",
    "    return img\n",
    "\n",
    "def imgtest(img):\n",
    "    predicted_img = predict(img)\n",
    "\n",
    "\n",
    "    return predicted_img\n",
    "\n",
    "def imgSave(img,num):\n",
    "    if not os.path.exists(\"./train/4\"):\n",
    "        os.mkdir(\"./train/4\")\n",
    "    face, rect = detect_face(img)\n",
    "    if not face is None:\n",
    "        cv2.imwrite(\"./train/4/\"+str(num)+\".jpg\", img[:,:,[2,1,0]])\n",
    "    return img, num\n",
    "\n",
    "def draw_text(img, text, x, y):\n",
    "    cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "    \n",
    "def get_distance():\n",
    "    number=[0]\n",
    "    distance_string=\"\"#距离的字符串形式\n",
    "    final_dis=0#距离的float类型\n",
    "    isdata=0\n",
    "    numcount=0\n",
    "    lib = MicroblazeLibrary(base.RPI, ['uart'])\n",
    "    device = lib.uart_open(14,15)\n",
    "    D = [0x46]\n",
    "    #控制命令\n",
    "    lib.uart_write(device,D,len(D))\n",
    "    sleep(0.1)\n",
    "    while(1):\n",
    "        lib.uart_read(device,number,len(number))\n",
    "        if number[0]!=10 and number[0]!=58:\n",
    "            if isdata and numcount!=0:\n",
    "                distance_string=distance_string+chr(number[0])\n",
    "                numcount = numcount-1\n",
    "            if number[0]==13:\n",
    "                isdata=1\n",
    "                numcount=7\n",
    "            if numcount==1:\n",
    "                isdata=0\n",
    "                distance_string=distance_string[0:6]\n",
    "                distance_string = distance_string.replace(' ','')\n",
    "                distance_string = distance_string.replace(',','')\n",
    "                distance_string = distance_string.replace('m','')\n",
    "                if ord(distance_string[0])>=48 and ord(distance_string[0])<58:\n",
    "                    final_dis=float(distance_string)\n",
    "                    device.close()\n",
    "                    return final_dis\n",
    "                else:\n",
    "                    return 0\n",
    "\n",
    "            \n",
    "def get_voltage():\n",
    "    #从自己加入的ip获取电压值\n",
    "    FS=4.096\n",
    "    while 1:  \n",
    "        input=base.rgbleds_gpio.channel2.read()\n",
    "        if input>0x8000:\n",
    "            input = 0x10000 - input\n",
    "            ADS1118_Voltage=-1*(input*FS / 0x8000)\n",
    "        else:\n",
    "            ADS1118_Voltage = input*FS /0x8000\n",
    "        return ADS1118_Voltage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "####################################################################################################       \n",
    "stage = 0\n",
    "num = 1\n",
    "face_recognizer = cv2.face.createLBPHFaceRecognizer()\n",
    "#建立标签与人名的映射列表（标签只能为整数）\n",
    "subjects = [\"Unknown\",\"Zhong\", \"Pan\",\"Huang\",\"testperson\"]\n",
    "faces, labels = prepare_training_data(\"train\")\n",
    "face_recognizer.train(faces, np.array(labels))\n",
    "nose_cascade = cv2.CascadeClassifier('/home/xilinx/jupyter_notebooks/base/video/data/''haarcascade_mcs_nose.xml')\n",
    "outframe = hdmi_out.newframe()\n",
    "distance = 0\n",
    "voltage = 0\n",
    "temperature = 0\n",
    "while True:\n",
    "    if base.buttons[0].read()==1 and base.switches.read()==0:\n",
    "        stage=1#口罩识别\n",
    "    if base.buttons[1].read()==1 and base.switches.read()==0:\n",
    "        stage=2#人脸检测\n",
    "    if base.buttons[2].read()==1 and base.switches.read()==0:\n",
    "        stage=3#人脸学习\n",
    "    if base.buttons[3].read()==1 and base.switches.read()==0:\n",
    "        stage=0#直接显示\n",
    "    if base.switches.read()==1:\n",
    "        stage=4#温度显示\n",
    "        \n",
    "    if stage == 0:\n",
    "        ret, np_frame = videoIn.read()\n",
    "        outframe[0:screen_h,0:screen_w,:] = np_frame[0:screen_h,0:screen_w,:]\n",
    "        hdmi_out.writeframe(outframe)\n",
    "    if stage == 1:\n",
    "        ret, np_frame = videoIn.read()\n",
    "        gray = cv2.cvtColor(np_frame, cv2.COLOR_BGR2GRAY)\n",
    "        noses = nose_cascade.detectMultiScale(gray)\n",
    "        if(len(noses)>=1):\n",
    "            draw_text(np_frame, 'Nomask',0,20)\n",
    "        outframe[0:screen_h,0:screen_w,:] = np_frame[0:screen_h,0:screen_w,:]\n",
    "        hdmi_out.writeframe(outframe)\n",
    "    if stage == 2:\n",
    "        ret, np_frame = videoIn.read()\n",
    "        np_frame = imgtest(np_frame)\n",
    "        outframe[0:screen_h,0:screen_w,:] = np_frame[0:screen_h,0:screen_w,:]\n",
    "        hdmi_out.writeframe(outframe)\n",
    "    if stage == 3:\n",
    "        ret, np_frame = videoIn.read()\n",
    "        outframe = hdmi_out.newframe()\n",
    "        outframe, num = imgSave(outframe, num)\n",
    "        draw_text(outframe, 'num:'+str(num),0,20)\n",
    "        print(num)\n",
    "        num = num + 1\n",
    "        outframe[0:screen_h,0:screen_w,:] = np_frame[0:screen_h,0:screen_w,:]\n",
    "        hdmi_out.writeframe(outframe)\n",
    "        if num>10:\n",
    "            faces, labels = prepare_training_data(\"train\")\n",
    "            face_recognizer.train(faces, np.array(labels))\n",
    "            stage = 0\n",
    "            num = 1\n",
    "    if stage ==4:\n",
    "        ret, np_frame = videoIn.read()\n",
    "        distance = get_distance()\n",
    "        voltage = get_voltage()\n",
    "        temperature =  30.47- 3.451*distance+3.093*voltage\n",
    "        draw_text(np_frame, 'distance:'+str(distance)+'m',0,20)\n",
    "        #draw_text(np_frame, 'voltage:'+str(voltage)[0:6]+'V',0,40)\n",
    "        draw_text(np_frame, 'temperature:'+str(temperature)[0:6]+'C',0,40)\n",
    "        if temperature>37:\n",
    "            pAudio.load(\"/home/xilinx/jupyter_notebooks/base/audio/temp.wav\")\n",
    "            pAudio.play()\n",
    "        outframe[0:screen_h,0:screen_w,:] = np_frame[0:screen_h,0:screen_w,:]\n",
    "        hdmi_out.writeframe(outframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-02d17b7a37cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhdmi_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mhdmi_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "videoIn.release()\n",
    "hdmi_out.stop()\n",
    "del hdmi_out\n",
    "device.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = MicroblazeLibrary(base.RPI, ['uart'])\n",
    "device = lib.uart_open(14,15)\n",
    "device.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
